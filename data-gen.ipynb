{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ea733dd-0d77-4aee-ac55-393782a2b382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minio in /opt/app-root/lib64/python3.11/site-packages (7.2.15)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.11/site-packages (from minio) (2025.1.31)\n",
      "Requirement already satisfied: urllib3 in /opt/app-root/lib64/python3.11/site-packages (from minio) (1.26.20)\n",
      "Requirement already satisfied: argon2-cffi in /opt/app-root/lib64/python3.11/site-packages (from minio) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/app-root/lib64/python3.11/site-packages (from minio) (3.22.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib64/python3.11/site-packages (from minio) (4.12.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/app-root/lib64/python3.11/site-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/app-root/lib64/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/app-root/lib64/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76f09279-e89c-4cc2-b99e-44364ea3ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import  os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11264bd-97e7-4962-a2df-e5e4740575fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinIO client doesn't like URLs with procotol/schema, so use\n",
    "# yourendpoint.com instead of https://yourtendpoint.com\n",
    "AWS_S3_ENDPOINT = os.getenv(\"AWS_S3_ENDPOINT\")\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3115be42-15be-4404-879e-2318e81f8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MinIO client\n",
    "client = Minio(\n",
    "    \"minio-svc.minio-store.svc.cluster.local:9000\",\n",
    "    access_key=AWS_ACCESS_KEY_ID,\n",
    "    secret_key=AWS_SECRET_ACCESS_KEY,\n",
    "    secure=False  # Set to True if you are using HTTPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab86ec0-9588-4399-9a99-38f239d2ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records generated: 1000008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207/343601996.py:134: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_df = df.groupby(customer_id_column, group_keys=False).apply(filter_customer_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records after filtering: 112425\n",
      "Number of churned customers: 27777\n",
      "         CustomerID BillingCycleStart BillingCycleEnd  CallMinutes  \\\n",
      "166668  CUST0000001        2020-07-01      2020-07-31          594   \n",
      "527783  CUST0000002        2021-08-01      2021-08-31          583   \n",
      "166670  CUST0000003        2020-07-01      2020-07-31          123   \n",
      "250005  CUST0000004        2020-10-01      2020-10-31          192   \n",
      "83338   CUST0000005        2020-04-01      2020-04-30          274   \n",
      "...             ...               ...             ...          ...   \n",
      "277775  CUST0027774        2020-10-01      2020-10-31          438   \n",
      "27774   CUST0027775        2020-01-01      2020-01-31          145   \n",
      "55553   CUST0027776        2020-02-01      2020-02-29          395   \n",
      "55554   CUST0027777        2020-02-01      2020-02-29          123   \n",
      "222223  CUST0027778        2020-08-01      2020-08-31          143   \n",
      "\n",
      "        DataUsageGB  SMSCount  InternetSessions  TotalBillAmount  \\\n",
      "166668        50.12       115                55            43.74   \n",
      "527783        98.49        67                44            70.29   \n",
      "166670        33.32       108                36            43.37   \n",
      "250005        97.91         5                18            34.34   \n",
      "83338         90.10       120                56           136.85   \n",
      "...             ...       ...               ...              ...   \n",
      "277775        42.47       168                 9            72.15   \n",
      "27774         37.92       134                32            90.25   \n",
      "55553         48.74        96                75            26.96   \n",
      "55554          5.89       183                14            48.34   \n",
      "222223        38.45       137                18            89.16   \n",
      "\n",
      "       PaymentStatus PaymentDueDate  LateFee  DiscountsApplied  \\\n",
      "166668          Paid     2020-08-05     0.00              2.14   \n",
      "527783        Unpaid     2021-09-05     7.41             10.45   \n",
      "166670          Paid     2020-08-05     0.00             18.16   \n",
      "250005          Paid     2020-11-05     0.00             13.89   \n",
      "83338           Paid     2020-05-05     0.00             11.43   \n",
      "...              ...            ...      ...               ...   \n",
      "277775          Paid     2020-11-05     0.00              6.80   \n",
      "27774           Paid     2020-02-05     0.00             19.32   \n",
      "55553           Paid     2020-03-05     0.00              5.40   \n",
      "55554           Paid     2020-03-05     0.00              8.39   \n",
      "222223          Paid     2020-09-05     0.00             17.49   \n",
      "\n",
      "        SupportInteractionCount LastInteractionDate PrimaryIssueType  \\\n",
      "166668                        5          2020-07-12        Technical   \n",
      "527783                        1          2021-08-31          Billing   \n",
      "166670                        4          2020-07-05  Service Quality   \n",
      "250005                        5          2020-10-02          Billing   \n",
      "83338                         2          2020-04-06        Technical   \n",
      "...                         ...                 ...              ...   \n",
      "277775                        5          2020-10-25          Billing   \n",
      "27774                         2          2020-01-19        Technical   \n",
      "55553                         5          2020-02-22          Billing   \n",
      "55554                         1          2020-02-24  Service Quality   \n",
      "222223                        5          2020-08-07          Billing   \n",
      "\n",
      "        ResolutionTimeMinutes  SatisfactionScore  EscalationFlag  \\\n",
      "166668                    101                  3           False   \n",
      "527783                    115                  2           False   \n",
      "166670                    103                  4           False   \n",
      "250005                     64                  2            True   \n",
      "83338                      93                  4           False   \n",
      "...                       ...                ...             ...   \n",
      "277775                     22                  2           False   \n",
      "27774                     114                  2           False   \n",
      "55553                     109                  5           False   \n",
      "55554                      18                  3            True   \n",
      "222223                    102                  5           False   \n",
      "\n",
      "       SupportChannel  HasChurned  \n",
      "166668           Chat        True  \n",
      "527783           Chat        True  \n",
      "166670          Phone        True  \n",
      "250005          Phone        True  \n",
      "83338           Email        True  \n",
      "...               ...         ...  \n",
      "277775          Phone        True  \n",
      "27774           Email        True  \n",
      "55553           Phone        True  \n",
      "55554           Email        True  \n",
      "222223           Chat        True  \n",
      "\n",
      "[27777 rows x 20 columns]\n",
      "Synthetic data generated and saved to 'synthetic_customer_data_evenly_distributed.csv'\n"
     ]
    }
   ],
   "source": [
    "# Author: Ã–mer Saatcioglu\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "num_months = 36\n",
    "unique_customers = 27778  # Fixed set of unique customers\n",
    "total_records = unique_customers * num_months  # 1,000,008 records\n",
    "churn_threshold = 0.6  # Churn risk score threshold for churn event\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Function: Last Day of Month\n",
    "# ---------------------------\n",
    "def last_day_of_month(dt: pd.Timestamp) -> datetime:\n",
    "    year, month = dt.year, dt.month\n",
    "    last_day = calendar.monthrange(year, month)[1]\n",
    "    return datetime(year, month, last_day)\n",
    "\n",
    "# ---------------------------\n",
    "# Calculate Churn Risk Score\n",
    "# ---------------------------\n",
    "def calculate_churn_risk(df: pd.DataFrame) -> pd.Series:\n",
    "    # Usage Patterns\n",
    "    # Lower call minutes, data usage, SMS, or internet sessions indicate lower engagement.\n",
    "    risk_call = (600 - df[\"CallMinutes\"]) / 500  # Expected range: 100 to 600\n",
    "    risk_data = (100 - df[\"DataUsageGB\"]) / 99     # Generated range: 1 to 100\n",
    "    risk_sms = (200 - df[\"SMSCount\"]) / 200         # Generated range: 0 to 200\n",
    "    risk_internet = (100 - df[\"InternetSessions\"]) / 100  # Generated range: 0 to 100\n",
    "\n",
    "    # Billing Information\n",
    "    # Higher bill amounts and late fees increase risk.\n",
    "    risk_bill = (df[\"TotalBillAmount\"] - 20) / 130  # Generated range: 20 to 150\n",
    "    payment_mapping = {\"Paid\": 0, \"Partial\": 0.5, \"Unpaid\": 1}\n",
    "    risk_payment = df[\"PaymentStatus\"].map(payment_mapping)\n",
    "    risk_late_fee = df[\"LateFee\"] / 20              # Generated range: 0 to ~20\n",
    "    # Receiving discounts should lower risk.\n",
    "    risk_discount = 1 - (df[\"DiscountsApplied\"] / 20)  # Generated range: 0 to 20\n",
    "\n",
    "    # Customer Support Interactions\n",
    "    risk_support = df[\"SupportInteractionCount\"] / 5  # Generated range: 0 to 5\n",
    "    # Map issue types to a risk factor. If no interaction, risk is 0.\n",
    "    issue_mapping = {\"\": 0, \"Billing\": 0.7, \"Technical\": 0.8, \"Service Quality\": 0.6}\n",
    "    risk_issue = df[\"PrimaryIssueType\"].map(issue_mapping).fillna(0)\n",
    "    # Longer resolution times are riskier; resolution time expected between 10 and 120 minutes.\n",
    "    risk_resolution = (df[\"ResolutionTimeMinutes\"] - 10) / 110\n",
    "    risk_resolution = risk_resolution.clip(lower=0)  # Ensure negative values don't occur.\n",
    "    # Lower satisfaction increases risk.\n",
    "    risk_satisfaction = (5 - df[\"SatisfactionScore\"]) / 4\n",
    "    # If an interaction was escalated, add risk.\n",
    "    risk_escalation = df[\"EscalationFlag\"].astype(int)  # True->1, False->0\n",
    "\n",
    "    # Define weights for each factor.\n",
    "    w_call = 0.1\n",
    "    w_data = 0.1\n",
    "    w_sms = 0.05\n",
    "    w_internet = 0.05\n",
    "    w_bill = 0.1\n",
    "    w_payment = 0.1\n",
    "    w_late_fee = 0.05\n",
    "    w_discount = 0.05\n",
    "    w_support = 0.1\n",
    "    w_issue = 0.05\n",
    "    w_resolution = 0.05\n",
    "    w_satisfaction = 0.15\n",
    "    w_escalation = 0.1\n",
    "\n",
    "    # Combine all risk factors into a final risk score.\n",
    "    risk_score = (\n",
    "        w_call * risk_call +\n",
    "        w_data * risk_data +\n",
    "        w_sms * risk_sms +\n",
    "        w_internet * risk_internet +\n",
    "        w_bill * risk_bill +\n",
    "        w_payment * risk_payment +\n",
    "        w_late_fee * risk_late_fee +\n",
    "        w_discount * risk_discount +\n",
    "        w_support * risk_support +\n",
    "        w_issue * risk_issue +\n",
    "        w_resolution * risk_resolution +\n",
    "        w_satisfaction * risk_satisfaction +\n",
    "        w_escalation * risk_escalation\n",
    "    )\n",
    "\n",
    "    # Inject random noise to lower the predictive accuracy (e.g., to around 75%)\n",
    "    # Adjust the scale parameter as needed to achieve the desired accuracy.\n",
    "    noise = np.random.normal(loc=0, scale=0.25, size=risk_score.shape)\n",
    "    noisy_risk_score = risk_score + noise\n",
    "\n",
    "    # Ensure the risk score is within [0, 1] and round to two decimals.\n",
    "    return noisy_risk_score.clip(0, 1).round(2)\n",
    "\n",
    "def filter_entries_after_churn(\n",
    "    data: pd.DataFrame,\n",
    "    date_column: str = \"BillingCycleStart\",\n",
    "    churn_flag: str = \"HasChurned\",\n",
    "    customer_id_column: str = \"CustomerID\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each customer, remove records that occur after the first occurrence of a churn event.\n",
    "    The record where HasChurned becomes True is retained, but all subsequent records for that customer are filtered out.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame with at least customer ID, a date column, and a churn flag.\n",
    "        date_column (str): The column name to use for ordering records (e.g., \"BillingCycleStart\").\n",
    "        churn_flag (str): The column name indicating if the customer has churned (boolean).\n",
    "        customer_id_column (str): The column name for the customer identifier.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame with entries after the churn event removed.\n",
    "    \"\"\"\n",
    "    # Work on a copy to avoid modifying the original DataFrame\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Ensure the date column is in datetime format and sort the DataFrame\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    df = df.sort_values(by=[customer_id_column, date_column])\n",
    "    \n",
    "    def filter_customer_group(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        if group[churn_flag].any():\n",
    "            # Find the first occurrence of churn\n",
    "            first_churn_date = group.loc[group[churn_flag], date_column].iloc[0]\n",
    "            # Keep records up to and including the churn event\n",
    "            return group[group[date_column] <= first_churn_date]\n",
    "        else:\n",
    "            return group\n",
    "\n",
    "    # Apply the filtering function for each customer\n",
    "    filtered_df = df.groupby(customer_id_column, group_keys=False).apply(filter_customer_group)\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Generate List of Billing Cycle Start Dates for 36 Months\n",
    "# ---------------------------\n",
    "billing_cycle_starts = pd.date_range(start=\"2020-01-01\", periods=num_months, freq=\"MS\")\n",
    "\n",
    "# Pre-generate unique customer IDs (the same set for each month to simulate time series)\n",
    "customer_ids = [f\"CUST{i:07d}\" for i in range(1, unique_customers + 1)]\n",
    "\n",
    "# List to store DataFrame for each month\n",
    "monthly_dfs = []\n",
    "\n",
    "# ---------------------------\n",
    "# Generate Data Month by Month\n",
    "# ---------------------------\n",
    "for month_start in billing_cycle_starts:\n",
    "    billing_start = month_start\n",
    "    billing_end = pd.Timestamp(last_day_of_month(month_start))\n",
    "    payment_due_date = billing_end + pd.Timedelta(days=5)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Usage Patterns\n",
    "    # ---------------------------\n",
    "    call_minutes = np.random.randint(100, 600, size=unique_customers)\n",
    "    data_usage = np.round(np.random.uniform(1, 100, size=unique_customers), 2)\n",
    "    sms_count = np.random.randint(0, 200, size=unique_customers)\n",
    "    internet_sessions = np.random.randint(0, 100, size=unique_customers)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Billing Information\n",
    "    # ---------------------------\n",
    "    total_bill_amount = np.round(np.random.uniform(20, 150, size=unique_customers), 2)\n",
    "    payment_status_options = [\"Paid\", \"Unpaid\", \"Partial\"]\n",
    "    payment_status_probs = [0.8, 0.1, 0.1]\n",
    "    payment_status = np.random.choice(payment_status_options, size=unique_customers, p=payment_status_probs)\n",
    "    \n",
    "    # Late fee: based on payment status.\n",
    "    late_fee = []\n",
    "    for status in payment_status:\n",
    "        if status == \"Paid\":\n",
    "            fee = 0.0\n",
    "        elif status == \"Unpaid\":\n",
    "            fee = round(random.uniform(5, 20), 2)\n",
    "        else:  # Partial\n",
    "            fee = round(random.uniform(1, 10), 2)\n",
    "        late_fee.append(fee)\n",
    "    late_fee = np.array(late_fee)\n",
    "    \n",
    "    discounts_applied = np.round(np.random.uniform(0, 20, size=unique_customers), 2)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Customer Support Interactions\n",
    "    # ---------------------------\n",
    "    support_interaction_count = np.random.randint(0, 6, size=unique_customers)\n",
    "    \n",
    "    last_interaction_date = []\n",
    "    primary_issue_type = []\n",
    "    resolution_time = []\n",
    "    satisfaction_score = []\n",
    "    escalation_flag = []\n",
    "    support_channel = []\n",
    "    \n",
    "    issue_types = [\"Billing\", \"Technical\", \"Service Quality\"]\n",
    "    support_channels = [\"Phone\", \"Chat\", \"Email\"]\n",
    "    \n",
    "    for count in support_interaction_count:\n",
    "        if count > 0:\n",
    "            # Random interaction date between billing_start and billing_end\n",
    "            delta_days = (billing_end - billing_start).days\n",
    "            random_day = random.randint(0, delta_days)\n",
    "            interaction_date = billing_start + pd.Timedelta(days=random_day)\n",
    "            last_interaction_date.append(interaction_date)\n",
    "            primary_issue_type.append(random.choice(issue_types))\n",
    "            resolution_time.append(random.randint(10, 120))\n",
    "            satisfaction_score.append(random.randint(1, 5))\n",
    "            escalation_flag.append(random.random() < 0.1)  # 10% chance of escalation\n",
    "            support_channel.append(random.choice(support_channels))\n",
    "        else:\n",
    "            last_interaction_date.append(pd.NaT)\n",
    "            primary_issue_type.append(\"\")\n",
    "            resolution_time.append(0)\n",
    "            satisfaction_score.append(5)  # Default high satisfaction if no interaction\n",
    "            escalation_flag.append(False)\n",
    "            support_channel.append(\"\")\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Create DataFrame for the Month\n",
    "    # ---------------------------\n",
    "    df_month = pd.DataFrame({\n",
    "        \"CustomerID\": customer_ids,  # Same set for every month\n",
    "        \"BillingCycleStart\": billing_start,\n",
    "        \"BillingCycleEnd\": billing_end,\n",
    "        \"CallMinutes\": call_minutes,\n",
    "        \"DataUsageGB\": data_usage,\n",
    "        \"SMSCount\": sms_count,\n",
    "        \"InternetSessions\": internet_sessions,\n",
    "        \"TotalBillAmount\": total_bill_amount,\n",
    "        \"PaymentStatus\": payment_status,\n",
    "        \"PaymentDueDate\": payment_due_date,\n",
    "        \"LateFee\": late_fee,\n",
    "        \"DiscountsApplied\": discounts_applied,\n",
    "        \"SupportInteractionCount\": support_interaction_count,\n",
    "        \"LastInteractionDate\": last_interaction_date,\n",
    "        \"PrimaryIssueType\": primary_issue_type,\n",
    "        \"ResolutionTimeMinutes\": resolution_time,\n",
    "        \"SatisfactionScore\": satisfaction_score,\n",
    "        \"EscalationFlag\": escalation_flag,\n",
    "        \"SupportChannel\": support_channel\n",
    "    })\n",
    "    \n",
    "    monthly_dfs.append(df_month)\n",
    "\n",
    "# Concatenate all monthly DataFrames into one final DataFrame\n",
    "df = pd.concat(monthly_dfs, ignore_index=True)\n",
    "print(f\"Total records generated: {len(df)}\")\n",
    "\n",
    "# Apply the churn risk function to compute the score for each record.\n",
    "df[\"HasChurned\"] = calculate_churn_risk(df) > churn_threshold\n",
    "\n",
    "# Filter out records after the first churn event for each customer\n",
    "df = filter_entries_after_churn(df)\n",
    "print(f\"Total records after filtering: {len(df)}\")\n",
    "\n",
    "churned_customers = df[df[\"HasChurned\"]]\n",
    "print(f\"Number of churned customers: {len(churned_customers)}\")\n",
    "print(churned_customers)\n",
    "\n",
    "# ---------------------------\n",
    "# Save the Synthetic Data\n",
    "# ---------------------------\n",
    "data_path = \"synthetic_customer_data_evenly_distributed.csv\"\n",
    "df.to_csv(data_path, index=False)\n",
    "print(f\"Synthetic data generated and saved to '{data_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69e41b3-3be7-4c4d-8ff6-17fb4f234d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data/synthetic_customer_data_evenly_distributed.csv' is successfully uploaded as object to bucket 'openshift'.\n"
     ]
    }
   ],
   "source": [
    "# Create File\n",
    "FILE_ON_DISK = 'synthetic_customer_data_evenly_distributed.csv'\n",
    "bucket_name = 'openshift'\n",
    "\n",
    "# Upload a File \n",
    "file_path = FILE_ON_DISK\n",
    "object_name = 'data/synthetic_customer_data_evenly_distributed.csv'\n",
    "\n",
    "try:\n",
    "    client.fput_object(AWS_S3_BUCKET, object_name, file_path)\n",
    "    print(f\"'{object_name}' is successfully uploaded as object to bucket '{bucket_name}'.\")\n",
    "except S3Error as e:\n",
    "    print(\"Error occurred: \", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
